<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="fi" xml:lang="fi">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta property="og:title" content="Kaavat bookdown-paketilla" />
<meta property="og:type" content="book" />





<meta name="author" content="Jussi Hirvonen" />


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>

<meta name="description" content="Kaavat bookdown-paketilla">

<title>Kaavat bookdown-paketilla</title>

<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="libs/navigation-1.1/tabsets.js"></script>





<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li class="has-sub"><a href="1-kaavat-ja-matemattiset-merkinnat.html#kaavat-ja-matemattiset-merkinnat"><span class="toc-section-number">1</span> Kaavat ja matemattiset merkinnät</a><ul>
<li><a href="1-1-kahden-luokittelumuuttuja-taulukko.html#kahden-luokittelumuuttuja-taulukko"><span class="toc-section-number">1.1</span> Kahden luokittelumuuttuja taulukko</a></li>
<li><a href="1-2-matriisit-ja-niiden-havainnollistaminen.html#matriisit-ja-niiden-havainnollistaminen"><span class="toc-section-number">1.2</span> Matriisit ja niiden havainnollistaminen</a></li>
<li><a href="1-3-korrespondenssianalyysin-perusyhtalot-ja-kaavat.html#korrespondenssianalyysin-perusyhtalot-ja-kaavat"><span class="toc-section-number">1.3</span> Korrespondenssianalyysin perusyhtälöt ja kaavat</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="korrespondenssianalyysin-perusyhtalot-ja-kaavat" class="section level2">
<h2><span class="header-section-number">1.3</span> Korrespondenssianalyysin perusyhtälöt ja kaavat</h2>
<p><strong>viitetiedot puuttuvat kaavoista</strong></p>
<p>Tässä lähteenä Greenacren kirja (ca in practice) ja sen liite Theory of CA. Muistiinpanoja löytyy, joissa viitataan myös Biplots in practice - kirjaan. Kevään 2017 kurssin luentokalvoja on myös käytetty. Lisäillään vielä käsitteitä LeRouxin ja Rouanetin kirjasta.</p>
<p>Datamatriisilla <span class="math inline">\(\boldsymbol{N}\)</span> on <span class="math inline">\(I\)</span> riviä ja <span class="math inline">\(J\)</span> sarakketta (<span class="math inline">\(I x J\)</span> ). Alkiot ovat ei-negatiivisia (eli nollat sallittuja) ja samassa mitta-asteikossa. Jos mitta-asteikko on intervalli- tai suhdeasteikko, mittayksiköiden on oltava samoja (esim. euroja, metrejä). Taulukon alkioiden summa on <span class="math inline">\(\sum_{i} \sum_{j}n_{ij} = n\)</span>, missä <span class="math inline">\(i = 1, \dots , I\)</span> ja <span class="math inline">\(j = 1, \dots , J\)</span>. GDA-kirjassa on tarkennettu tätä vaatimusta ei-negatiivisuudesta.</p>
<p>Korrespondenssimatriisi <span class="math inline">\(\boldsymbol{P}\)</span> saadaan jakamalla matriisin <span class="math inline">\(\boldsymbol{N}\)</span> alkiot niiden summalla <span class="math inline">\(n\)</span> .
Merkitään matriisin <span class="math inline">\(\boldsymbol{P}\)</span> rivisummien vektoria <span class="math inline">\(\boldsymbol{r}\)</span> (= <span class="math inline">\((r_{1}, \dots, r_{I})\)</span>) ja sarakesummien vektoria <span class="math inline">\(\boldsymbol{c}\)</span> (=
<span class="math inline">\((c_{1}, \dots, c_{J})\)</span>). Niitä vastaavat diagonaalimatriisit ovat <span class="math inline">\(\boldsymbol{D_r}\)</span> ja <span class="math inline">\(\boldsymbol{D_c}\)</span>.</p>
<p>Korrespondenssianalyysin perusrakenne (algoritmi?) on tämä. Singulaariarvohajoitelma (singular value decomposition) tuottaa ratkaisun kun sitä sovelletaan standardoituun residuaalimatriisiin <span class="math inline">\(\boldsymbol{S}\)</span>.</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{S} = \boldsymbol{D_r}^{-1/2}(\boldsymbol{P} - \boldsymbol{r}\boldsymbol{c}^T)\boldsymbol{D_c}^{-1/2} \label{A}
\end{equation}\]</span></p>
<p>Residuaalimatriisi voidaan esittää myös ns. kontingenssi-suhdelukujen (contingency ratio) avulla.</p>
<p><span class="math display">\[
\boldsymbol{D_r}^{-1} \boldsymbol{P} \boldsymbol{D_c}^{-1} = \left( \frac{p_{ij}} {r_{i} c{j}} \right)
\]</span></p>
<p><span class="math display">\[ 
\boldsymbol{S} = \boldsymbol{D_r}^{1/2} (\boldsymbol{D_r}^{-1} \boldsymbol{P} \boldsymbol{D_c}^{-1} - \boldsymbol{1}\boldsymbol{1}^{T} ) \boldsymbol{D_c}^{-1/2}  \;\;\; .
\]</span></p>
<p>Toinen esitystapa on hyödyllinen, kun tarkastellaan CA:n yhteyksiä muihin läheisiin menetelmiin (log ratio analysis of compositional data, moniulotteinen skaalaus (?), lineaarinen diskriminanttianalyysi, kanoninen korrelaatioanalyysi, pääkomponettianalyysi, kaksoiskuvat, yleensä SVD-perusteiset dimensioden vähentämisen menetelmät).</p>
<p><span class="math display">\[
s_{ij} = \frac{p_{ij}-r_{i}c_{j}} { \sqrt{r_{i}c_{j} } }
\]</span></p>
<p>ja toinen
<span class="math display">\[
s_{ij} = \sqrt{r_{i}} \left( \frac{p_{ij}}{r_{i}c_{j}} \right) \sqrt{c_{j}} \;\;\; .
\]</span></p>
<p>Mitäköhän tuosta pitäisi nähdä? Selitykset löytyvät em. teorialiitteestä.</p>
<p>Singulaariarvohajoitelma (singular value decomposition, SVD) matriisille <span class="math inline">\(\boldsymbol{S}\)</span> on</p>
<p><span class="math display">\[ 
\boldsymbol{S} = \boldsymbol{U} \boldsymbol{D_{\alpha}} \boldsymbol{V}^{T}
\]</span></p>
<p>missä <span class="math inline">\(\boldsymbol{D_{\alpha}}\)</span> on diagonaalimatriisi, jonka alkiot ovat singulaariarvot suuruusjärjestyksessä <span class="math inline">\(\alpha_{1}\geq \alpha_{1} \geq \hdots\)</span></p>
<p>Matriisit <span class="math inline">\(\boldsymbol{U}\)</span> ja <span class="math inline">\(\boldsymbol{V}\)</span> ovat ortogonaalisia singulaarivektoreiden matriiseja. Singulaariarvohajoitelman merkitys dimensioiden vähentämiselle perustuu Eckart - Young - teoreemaan. Teoreema (30-luvulta?) kertoo, että saamme pienimmän neliösumman <span class="math inline">\(m\)</span> - ulotteisen approksimaation matriisille <span class="math inline">\(\boldsymbol{S}\)</span> (CAinP, ss. 244) matriisien
<span class="math inline">\(\boldsymbol{U}\)</span> ja <span class="math inline">\(\boldsymbol{V}\)</span> ensimmäisten sarakkeiden ja ensimmäisten singulaariarvojen avulla.</p>
<p><span class="math display">\[
\boldsymbol{S}_{(m)} = \boldsymbol{U}_{(m)} \boldsymbol{D}_{\alpha(m)} \boldsymbol{V}_{(m)}^{T}
\]</span></p>
<p>Korrrespondenssianalyysin ratkaisualgoritmissa tätä tulosta on muokattava niin, että rivien ja sarakkeiden massat huomioidaan pienimmän neliösumman approksimaatiossa painoina.</p>
<p>Näin saadaan standardikoordinaatit ja principal-koordinaatit riveille ja sarakkeille.</p>
<p>Rivien standardikoordinaatit
<span class="math display">\[\begin{equation}
\boldsymbol{\Phi} = \boldsymbol{D_r}^{-\frac{1}{2}} \boldsymbol{U} \label{B} 
\end{equation}\]</span></p>
<p>Sarakkeiden standardikoordinaatit
<span class="math display">\[\begin{equation}
 \boldsymbol{\Gamma} = \boldsymbol{D_c}^{-\frac{1}{2}} \boldsymbol{V} \label{C}
\end{equation}\]</span></p>
<p>Rivien principal-koordinaatit
<span class="math display">\[\begin{equation}
 \boldsymbol{F} =   \boldsymbol{D_r}^{-\frac{1}{2}} \boldsymbol{U}  \boldsymbol{D_{\alpha}} = \boldsymbol{\Phi} \boldsymbol{D_{\alpha}} \label{D}
\end{equation}\]</span></p>
<p>Sarakkeiden principal-koordinaatit
<span class="math display">\[\begin{equation}
 \boldsymbol{G}  = \boldsymbol{D_c}^{-\frac{1}{2}} \boldsymbol{V} \boldsymbol{D_{\alpha}} = \boldsymbol{\Gamma}  \boldsymbol{D_{\alpha}} \label{E}
\end{equation}\]</span></p>
<p>Pääakseleiden inertiat (principal inertias) <span class="math inline">\(\lambda_{k}\)</span></p>
<p><span class="math display">\[\begin{equation}
\lambda_{k} = \alpha_{k}^2, k = 1,\dots,K,
K = min \{ I-1, J-1 \}
\end{equation}\]</span></p>
<p>Bilineaarinen korresepondenssimalli</p>
<p>Korrespondenssimatriisi <span class="math inline">\(\boldsymbol{P}\)</span> voidaan esittää matriisi- ja alkiomuodossa ns. palautuskaavana (reconstitution formula).</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{P} = \boldsymbol{D}_{r} \left( \boldsymbol{1}\boldsymbol{1}^{T} + \boldsymbol{\Phi}\boldsymbol{D}_{\lambda}^{\frac {1}{2}}\boldsymbol{\Gamma}^{T}\right)\boldsymbol{D}_{c}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
p_ {ij}= r_{i}c_{j} \left(1 + \sum_{k=1}^{K} \sqrt{\lambda_{k}} \phi_{ik} \gamma_{jk} \right)
\end{equation}\]</span></p>
<p>Tässä viitataan s. 101 (13.4), 109 (14.9), ja 109-110 (14.10 ja 14.11). Palautuskavoilla on monta esitystapaa bilineaarisessa mallissa.</p>
<p>Rivien ja sarakkeiden riippuvuus ja transitioyhtälöt. ss. 244, 108-109 skalaariversiot.</p>
<p>Pääkoordinaatit standardikoordinaattien funktiona (ns. barysentrinen ominaisuus - barycentric relationships)</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{F} = \boldsymbol{D}_{r}^{-1} \boldsymbol{P}\boldsymbol{\Gamma}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{G} = \boldsymbol{D}_{c}^{-1} \boldsymbol{P}^{T}\boldsymbol{\Phi}
\end{equation}\]</span></p>
<p>Pääkoordinaatit pääkoordinaattien funktiointa:</p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{F} = \boldsymbol{D}_{r}^{-1} \boldsymbol{P}\boldsymbol{G}\boldsymbol{D}_{\lambda}^{-\frac{1}{2}}
\end{equation}\]</span></p>
<p><span class="math display">\[\begin{equation}
\boldsymbol{G} = \boldsymbol{D}_{c}^{-1} \boldsymbol{P}^{T}\boldsymbol{F}\boldsymbol{D}_{\lambda}^{-\frac{1}{2}}
\end{equation}\]</span></p>
<p>Yhtälöt (9) ja (10) esittävät profiilipisteet ideaalipisteiden (vertex points) painotettuina keskiarvoina, painoina profiilin elementit. Asymmetriset kartat (rivien tai sarakkeiden suhteen) perustuvat näihin yhtälöihin. Yhtälöiden (11) ja (12) kahdet pääkoordinaatit ovat perusta symmetrisille kartoille. Myös niitä yhdistää barisentrinen painotetun keskiarvon riippuvuus, mutta mukana ovat skaalaustekijät
<span class="math inline">\(\frac{1}{\sqrt{\lambda_{i}}}\)</span>. Ne ovat jokaisessa dimensiossa eri suuruisia.</p>
<p>Kokeillaan vielä kaavaviitteitä: kaavojen <a href="1-1-kahden-luokittelumuuttuja-taulukko.html#eq:khii21">(1.1)</a> ja <a href="1-1-kahden-luokittelumuuttuja-taulukko.html#eq:khii22">(1.2)</a> yhteyden pitäisi olla selkeä.</p>
</div>
<!-- </div> -->
<p style="text-align: center;">
<a href="1-2-matriisit-ja-niiden-havainnollistaminen.html"><button class="btn btn-default">Previous</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
